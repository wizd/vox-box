services:
  # 语音识别 (Speech-to-Text) - 支持中文
  # faster-whisper-large-v3: 最佳多语言模型，中文识别效果优秀
  vox-stt:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: vox-stt
    ports:
      - "8080:80"
    volumes:
      - vox-stt-data:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command:
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "80"
      - "--device"
      - "cuda:0"
      - "--huggingface-repo-id"
      - "Systran/faster-whisper-large-v3"
      - "--data-dir"
      - "/data"
    restart: unless-stopped

  # 语音合成 (Text-to-Speech) - 支持中文
  # CosyVoice-300M-SFT: 高质量中文语音合成模型（已验证 Linux 支持）
  vox-tts:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: vox-tts
    ports:
      - "8082:80"
    volumes:
      - vox-tts-data:/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command:
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "80"
      - "--device"
      - "cuda:0"
      - "--huggingface-repo-id"
      - "FunAudioLLM/CosyVoice-300M-SFT"
      - "--data-dir"
      - "/data"
    restart: unless-stopped

  # Qwen3-TTS - 高性能低延迟中文语音合成 (vLLM-Omni)
  # 独立服务，与 CosyVoice 并存，API 兼容 OpenAI /v1/audio/speech
  qwen3-tts:
    image: vllm/vllm-omni:v0.14.0
    container_name: qwen3-tts
    ports:
      - "8083:8000"
    volumes:
      - qwen3-tts-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ipc: host
    entrypoint: ["vllm", "serve", "--omni"]
    command:
      - "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "8000"
      - "--gpu-memory-utilization"
      - "0.5"
      - "--trust-remote-code"
      - "--enforce-eager"
    restart: unless-stopped

  # CosyVoice3 - 高性能流式中文语音合成 (Fun-CosyVoice3-0.5B)
  # OpenAI 兼容 API, 流式 PCM, ~1.2s TTFB
  # 基于 neosun/cosyvoice:v3.4.0 升级 PyTorch 以支持 RTX 5090 Blackwell
  cosyvoice3:
    build:
      context: .
      dockerfile: Dockerfile.cosyvoice3
    container_name: cosyvoice3
    ports:
      - "8188:8188"
    volumes:
      - cosyvoice3-voices:/data/voices
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
    restart: unless-stopped

  # CosyVoice2 TRT-LLM - 极致低延迟流式 TTS (Triton + TensorRT-LLM)
  # 流式 TTFB ~190ms, RTF < 0.15, gRPC streaming
  # 首次启动需下载模型 + 编译 TRT 引擎，约 30-60 分钟
  cosyvoice2-trt:
    image: soar97/triton-cosyvoice:25.06
    container_name: cosyvoice2-trt
    ipc: host
    shm_size: '2gb'
    ports:
      - "8000:8000"   # Triton HTTP
      - "8001:8001"   # Triton gRPC (流式推荐)
      - "8002:8002"   # Triton metrics
    volumes:
      - cosyvoice2-trt-data:/workspace/persist
      - ./scripts/patch_cosyvoice2_token2wav.py:/workspace/patches/patch_cosyvoice2_token2wav.py:ro
    environment:
      - PYTHONIOENCODING=utf-8
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    command: >
      /bin/bash -c "
        set -e &&
        PERSIST=/workspace/persist &&

        echo '=== Step 1: Clone CosyVoice repo ===' &&
        if [ ! -d $$PERSIST/CosyVoice ]; then
          git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git $$PERSIST/CosyVoice ;
        fi &&
        ln -sfn $$PERSIST/CosyVoice /workspace/CosyVoice &&

        echo '=== Step 1.5: Patch token2wav template for short mel ===' &&
        python3 /workspace/patches/patch_cosyvoice2_token2wav.py --target $$PERSIST/CosyVoice/runtime/triton_trtllm/model_repo/token2wav/1/model.py &&

        cd /workspace/CosyVoice/runtime/triton_trtllm &&

        echo '=== Step 2: Download models from HuggingFace ===' &&
        if [ ! -f cosyvoice2_llm/model.safetensors ]; then
          huggingface-cli download --local-dir cosyvoice2_llm yuekai/cosyvoice2_llm ;
        fi &&
        if [ ! -f CosyVoice2-0.5B/cosyvoice2.yaml ]; then
          huggingface-cli download --local-dir CosyVoice2-0.5B FunAudioLLM/CosyVoice2-0.5B ;
        fi &&
        if [ ! -f CosyVoice2-0.5B/spk2info.pt ]; then
          wget -q https://raw.githubusercontent.com/qi-hua/async_cosyvoice/main/CosyVoice2-0.5B/spk2info.pt -O CosyVoice2-0.5B/spk2info.pt ;
        fi &&

        echo '=== Step 3: Build TRT engines ===' &&
        if [ ! -f trt_engines_bfloat16/rank0.engine ]; then
          bash run.sh 1 1 ;
        fi &&

        echo '=== Step 4: Create model repo + Start Triton ===' &&
        bash run.sh 2 3
      "
    restart: unless-stopped

  # CosyVoice2 OpenAI-Compatible HTTP Bridge
  # 将 /v1/audio/speech API 转发到 Triton gRPC，返回流式 WAV/PCM
  cosyvoice2-bridge:
    build:
      context: .
      dockerfile: Dockerfile.cosyvoice2-bridge
    container_name: cosyvoice2-bridge
    ports:
      - "9880:9880"
    depends_on:
      - cosyvoice2-trt
    restart: unless-stopped

volumes:
  vox-stt-data:
  vox-tts-data:
  qwen3-tts-cache:
  cosyvoice3-voices:
  cosyvoice2-trt-data: